{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Electrophysiology introduction\n","This notebook introduces EEG data analysis by walking through computing an event-related potential (ERP). We import an example dataset containing an intracranial recording from a subject engaged in a visual target detection task, and compute the ERP in response to a target and a standard stimulus. Standard packages (numpy, scipy, and matplotlib) are introduced; basic printing and plotting are demonstrated; and an intuitive analysis requiring indexing and averaging is provided."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Set-up"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Download data / code repository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1278,"status":"ok","timestamp":1688424576074,"user":{"displayName":"Michael Preston","userId":"05461865459797412322"},"user_tz":420},"id":"J3wiG-_T3PlG","outputId":"6116a390-f550-41b0-f652-1c4490703529"},"outputs":[],"source":["# We begin by 'cloning' the GitHub repository for this workshop.\n","# This will download the data we will be analyzing in this notebook\n","!git clone https://github.com/mwprestonjr/ephys_workshop.git\n","%cd ephys_workshop"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Import packages"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1688424576075,"user":{"displayName":"Michael Preston","userId":"05461865459797412322"},"user_tz":420},"id":"OeCSuyb43gM-"},"outputs":[],"source":["# Next we import the necessary packages for our analysis\n","import numpy as np # for general computing\n","import matplotlib.pyplot as plt # for plotting\n","import scipy.io as sio # for loading data\n"]},{"cell_type":"markdown","metadata":{},"source":["### Intro: target detection task"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Target detection task design: The subject sequentially views a series of visual stimuli. 80% of the stimuli are 'standard stimuli' while 20% are 'target stimuli.' The subject must respond via a button press whenever the target stimuli is presented. This classic task has been used to investigate visual perception and attention."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![](./figures/target_detection_task.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1688424576075,"user":{"displayName":"Michael Preston","userId":"05461865459797412322"},"user_tz":420},"id":"r3E81XXd3fiV","outputId":"09375dd8-ec15-46a2-be91-38b1fb96fe6b"},"outputs":[],"source":["# Here we load the example dataset. This dataset contains an intracranial EEG\n","# recording (one channel) from a subject engaged in a target detection task.\n","\n","# Use scipy to load dataset (dictionary containing experimental data)\n","data_in = sio.loadmat('data/ecog_data.mat', squeeze_me=True)\n","\n","# Assign neural and behavioral data arrays to variables\n","eeg = data_in['data'] # Neural data from one channel (voltage v. time)\n","standard_stim = data_in['sta'] # Time index of standard stimuli events\n","target_stim = data_in['tar'] # Time index of target stimuli event \n","response = data_in['resp'] # Time index of behavioral responses\n","\n","# print dataset details\n","print(f\"N EEG data points: {len(eeg)}\")\n","print(f\"N standard stimuli: {len(standard_stim)}\")\n","print(f\"N target stimuli: {len(target_stim)}\")\n","print(f\"N response times: {len(response)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show data array\n","print(eeg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use matplotlib to visualize EEG data\n","plt.plot(eeg);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1688424576447,"user":{"displayName":"Michael Preston","userId":"05461865459797412322"},"user_tz":420},"id":"PcxKKE1E5Lmk","outputId":"1ff75659-d435-42f6-9bcc-91a939281c14"},"outputs":[],"source":["# Plot EEG time-series\n","\n","# plot EEG time-series\n","plt.figure(figsize=[12,4])\n","plt.plot(eeg)\n","plt.xlabel('Sample #')\n","plt.ylabel('Voltage')\n","plt.show()\n","\n","# plot EEG time-series snippet\n","plt.figure(figsize=[12,4])\n","plt.plot(eeg[:3000]) # indexing: get first 3000 samples\n","plt.xlabel('Sample #')\n","plt.ylabel('Voltage')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define time points for EEG data\n","\n","# set sampling frequency: the data is sampled at 1000 samples per second (1000 Hz)\n","fs = 1000\n","\n","# use numpy to define time vector\n","time_points = np.arange(len(eeg)) / fs # samples / (samples/second) = seconds\n","print(f\"Shape of 'eeg': {eeg.shape}\")\n","print(f\"Shape of 'time_points': {time_points.shape}\")\n","print(f\"\\nSignal duration: {time_points[-1]:.2f} seconds\\n\")\n","print(time_points)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Visualize EEG time-series\n","\n","# plot fullEEG time-series\n","plt.figure(figsize=[12,4])\n","plt.plot(time_points, eeg)\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.show()\n","\n","# plot EEG time-series snippet\n","plt.figure(figsize=[12,4])\n","plt.plot(time_points, eeg)\n","plt.xlim((15,18)) # limit x-range to show 3 second snippet of data only\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# visualize stimulus data\n","\n","# show array\n","print(standard_stim[:10])\n","\n","# plot stimulus times\n","plt.figure(figsize=[12,4])\n","plt.eventplot(standard_stim / fs, color='grey') # dividing by the sampling frequnecy (fs) converts the index to time in seconds\n","plt.eventplot(target_stim / fs, color='r')\n","plt.xlim((400, 500)) \n","plt.xlabel('Time (s)')\n","plt.yticks([])\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ys3PY7pv_Qc7"},"source":["## Event-related potential (ERP) analysis\n","In this section we will compute and plot the ERP. We will compare the ERP in response to the target and standard stimuli. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot response to target stimuli\n","\n","# get data window (epoch) around stimulus time\n","time_window = 1 * fs # take 1 second window before/after the stimulus time\n","idx_stim = target_stim[0] # get index of first stimuli\n","idx_start = idx_stim - time_window # index of epoch start\n","idx_end =  idx_stim + time_window # index of epoch end\n","erp_0 = eeg[idx_start : idx_end] # get ERP response to first target stimuli\n","erp_time = time_points[idx_start : idx_end] # get associated time points\n","\n","# print details\n","print(f\"Time of first target stimuli: {target_stim[0] / fs} s\")\n","print(f\"Start index: {idx_start}, End index: {idx_end}\")\n","print(f\"ERP shape: {erp_0.shape}\")\n","print(f\"Time shape: {erp_time.shape}\")\n","\n","# plot\n","plt.plot(...) # plot ERP\n","plt.axvline(idx_stim/fs, linestyle='--', color='k') # draw vertical line at stimulus time\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We see that the evoked response on a single trial is quite small and difficult to serarate from noise. Next, we will compute the ERP by averaging over many responses to the same stimulus. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# compute average response to target stimulus\n","\n","# initialize matrix to store response to each stimuli\n","n_samples = time_window * 2\n","evoked_responses = np.zeros([len(target_stim), n_samples]) \n","print(f\"Shape of 'evoked_responses': {evoked_responses.shape}\")\n","\n","# loop through each stimulus and store response\n","for ii, idx_stim in enumerate(target_stim):\n","    idx_stim = target_stim[ii] # get index of current stimuli\n","    idx_start = idx_stim - time_window\n","    idx_end =  idx_stim + time_window\n","    evoked_responses[ii] = eeg[idx_start : idx_end] # get ERP response to current target stimuli and store\n","\n","# average response across trials\n","erp = np.mean(evoked_responses, axis=0)\n","print(f\"Shape of 'erp': {erp.shape}\")\n","\n","# plot individual responses and mean ERP\n","erp_time = (np.arange(len(erp))/fs) - (time_window/fs) # define time vector\n","plt.plot(erp_time, evoked_responses.T, color='grey', linewidth=1) # plot ERP\n","plt.plot(erp_time, erp, color='k', linewidth=3, label='mean ERP') # plot ERP\n","plt.axvline(0, linestyle='--', color='k') # draw vertical line at stimulus time\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.legend()\n","plt.show()\n","\n","# plot ERP \n","plt.figure()\n","plt.plot(erp_time, erp) # plot ERP\n","plt.axvline(0, linestyle='--', color='k') # draw vertical line at stimulus time\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define function to compute ERP\n","\n","def compute_erp(data, stim_times, time_window):\n","    \"\"\"\n","    Compute event-related potential (ERP) from neural data i.e. the average \n","    response to a stimulus.\n","    \n","    Parameters\n","    ----------\n","    data : array\n","        1D array of neural data\n","    stim_times : array\n","        1D array of stimulus times\n","    time_window : int\n","        Window size (in samples) around each stimulus time\n","        \n","    Returns\n","    -------\n","    erp : array\n","        1D array of ERP\n","    \"\"\"\n","    \n","    # preallocate array for ERP\n","    evoked_response = np.zeros((len(stim_times), time_window*2))\n","    \n","    # loop through each stimulus time\n","    for i, stim_time in enumerate(stim_times):\n","        \n","        # get data window (epoch) around stimulus time\n","        idx_start = stim_time - time_window\n","        idx_end =  stim_time + time_window\n","        evoked_response[i] = data[idx_start : idx_end]\n","\n","    # average across stimuli\n","    erp = np.mean(evoked_response, axis=0)\n","\n","    return erp"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# compare ERP of target and response stimulus\n","\n","# compute ERP for target and standard stimuli\n","erp_target = compute_erp(...)\n","erp_standard = compute_erp(...)\n","\n","# print shapes of ERP arrays\n","print(f\"Shape of 'erp_target': {erp_target.shape}\")\n","print(f\"Shape of 'erp_standard': {erp_standard.shape}\")\n","\n","# plot ERPs\n","plt.figure()\n","plt.plot(..., label='target') # plot ERP for target stimulus\n","plt.plot(..., label='standard') # plot ERP for standard stimulus\n","plt.axvline(0, linestyle='--', color='k') # draw vertical line at stimulus time\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot ERPs - zoomed in on stimulus time\n","plt.figure()\n","plt.plot(..., label='target')\n","plt.plot(..., label='standard') \n","plt.axvline(0, linestyle='--', color='k')\n","plt.xlabel('Time (s)')\n","plt.ylabel('Voltage')\n","plt.xlim((-0.2, 0.5)) # zoom in on stimulus time\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO4TlDPlmuRkFKjJjvgpVIf","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
